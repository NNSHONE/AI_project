from transformers import AutoImageProcessor, SiglipForImageClassification
from PIL import Image, ImageDraw
import torch
import os

# 1. ì¤‘ì•™ ë§ˆìŠ¤í‚¹ í•¨ìˆ˜
def apply_center_mask(image, mask_ratio=0.3):
    """
    ì´ë¯¸ì§€ ì¤‘ì•™ì— ê²€ì€ìƒ‰ ì‚¬ê°í˜• ë§ˆìŠ¤í¬ ì ìš©
    
    Args:
        image: PIL Image ê°ì²´
        mask_ratio: ë§ˆìŠ¤í¬ í¬ê¸° ë¹„ìœ¨ (0.3 = ì´ë¯¸ì§€ì˜ 30%)
    
    Returns:
        ë§ˆìŠ¤í‚¹ëœ PIL Image
    """
    img_copy = image.copy()
    draw = ImageDraw.Draw(img_copy)
    
    width, height = img_copy.size
    
    # ì¤‘ì•™ ë§ˆìŠ¤í¬ ì˜ì—­ ê³„ì‚°
    mask_width = int(width * mask_ratio)
    mask_height = int(height * mask_ratio)
    
    left = (width - mask_width) // 2
    top = (height - mask_height) // 2
    right = left + mask_width
    bottom = top + mask_height
    
    # ê²€ì€ìƒ‰ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
    draw.rectangle([left, top, right, bottom], fill='black')
    
    return img_copy

# í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
TRAINED_MODEL_PATH = "/workspace/indooroutdoor_dataset/final_model"

# í•™ìŠµëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
if os.path.exists(TRAINED_MODEL_PATH):
    print(f"âœ… í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ: {TRAINED_MODEL_PATH}")
    model_name = TRAINED_MODEL_PATH
else:
    print("âš ï¸  í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: prithivMLmods/IndoorOutdoorNet")
    model_name = "prithivMLmods/IndoorOutdoorNet"

# Load model and processor
model = SiglipForImageClassification.from_pretrained(model_name)
processor = AutoImageProcessor.from_pretrained(model_name)

def classify_environment(image_path_or_pil, use_center_mask=False, mask_ratio=0.6):
    """
    ì‹¤ë‚´/ì‹¤ì™¸ í™˜ê²½ ë¶„ë¥˜
    
    Args:
        image_path_or_pil: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ(str) ë˜ëŠ” PIL Image ê°ì²´
        use_center_mask: ì¤‘ì•™ ë§ˆìŠ¤í‚¹ ì‚¬ìš© ì—¬ë¶€ (í•™ìŠµ ì‹œì™€ ë™ì¼í•˜ê²Œ ì„¤ì •)
        mask_ratio: ë§ˆìŠ¤í¬ í¬ê¸° ë¹„ìœ¨
        
    Returns:
        dict: {"environment": "Indoor" or "Outdoor", "confidence": float, "scores": dict}
    """
    # PIL Imageë¡œ ë³€í™˜
    if isinstance(image_path_or_pil, str):
        image = Image.open(image_path_or_pil).convert("RGB")
    else:
        image = image_path_or_pil.convert("RGB")
    
    # ì¤‘ì•™ ë§ˆìŠ¤í‚¹ ì ìš© (í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ì „ì²˜ë¦¬)
    if use_center_mask:
        image = apply_center_mask(image, mask_ratio)
    
    inputs = processor(images=image, return_tensors="pt")
    
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.nn.functional.softmax(logits, dim=1).squeeze().tolist()
    
    # ê²°ê³¼ ì •ë¦¬
    indoor_score = probs[0]
    outdoor_score = probs[1]
    
    environment = "Indoor" if indoor_score > outdoor_score else "Outdoor"
    confidence = max(indoor_score, outdoor_score)
    
    return {
        "environment": environment,
        "confidence": round(confidence, 4),
        "scores": {
            "Indoor": round(indoor_score, 4),
            "Outdoor": round(outdoor_score, 4)
        }
    }

# ë‚˜ë¨¸ì§€ í‰ê°€ í•¨ìˆ˜ë“¤...
def prepare_val_data(data_dir):
    """
    ë°ì´í„° í´ë” êµ¬ì¡°:
    data_dir/
      â”œâ”€â”€ test_indoor/
      â”‚   â”œâ”€â”€ img1.jpg
      â”‚   â”œâ”€â”€ img2.jpg
      â”‚   â””â”€â”€ ...
      â””â”€â”€ test_outdoor/
          â”œâ”€â”€ img1.jpg
          â”œâ”€â”€ img2.jpg
          â””â”€â”€ ...
    """
    image_paths = []
    labels = []
    
    # Indoor images (label=0)
    indoor_dir = os.path.join(data_dir, "test_indoor")
    if os.path.exists(indoor_dir):
        for img_name in os.listdir(indoor_dir):
            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                image_paths.append(os.path.join(indoor_dir, img_name))
                labels.append(0)
    
    # Outdoor images (label=1)
    outdoor_dir = os.path.join(data_dir, "test_outdoor")
    if os.path.exists(outdoor_dir):
        for img_name in os.listdir(outdoor_dir):
            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                image_paths.append(os.path.join(outdoor_dir, img_name))
                labels.append(1)
    
    return image_paths, labels

def evaluate_model(model_path, data_dir, use_center_mask=True, mask_ratio=0.3):
    """
    Validation ë°ì´í„°ì…‹ì— ëŒ€í•´ ì „ì²´ í‰ê°€ ìˆ˜í–‰
    
    Args:
        model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
        data_dir: ë°ì´í„°ì…‹ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
        use_center_mask: ì¤‘ì•™ ë§ˆìŠ¤í‚¹ ì‚¬ìš© ì—¬ë¶€
        mask_ratio: ë§ˆìŠ¤í¬ í¬ê¸° ë¹„ìœ¨
    
    Returns:
        dict: í‰ê°€ ê²°ê³¼ (accuracy, confusion matrix ë“±)
    """
    from sklearn.metrics import confusion_matrix, classification_report
    import json
    
    # ëª¨ë¸ ë¡œë“œ
    processor = AutoImageProcessor.from_pretrained(model_path)
    model = SiglipForImageClassification.from_pretrained(model_path)
    model.eval()
    
    # ë°ì´í„° ì¤€ë¹„
    val_paths, val_labels = prepare_val_data(data_dir)
    
    if len(val_paths) == 0:
        print(f"âŒ ì˜¤ë¥˜: {data_dir}ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"í´ë” êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”: {data_dir}/test_indoor/ ë° {data_dir}/test_outdoor/")
        return None
    
    print(f"Validation ë°ì´í„°ì…‹ í¬ê¸°: {len(val_paths)}")
    print(f"Indoor: {val_labels.count(0)}, Outdoor: {val_labels.count(1)}")
    print(f"ë§ˆìŠ¤í‚¹ ì‚¬ìš©: {use_center_mask}, ë¹„ìœ¨: {mask_ratio if use_center_mask else 'N/A'}")
    print("-" * 60)
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    predictions = []
    true_labels = []
    incorrect_samples = []
    
    for idx, (img_path, true_label) in enumerate(zip(val_paths, val_labels)):
        try:
            image = Image.open(img_path).convert("RGB")
            
            # ì¤‘ì•™ ë§ˆìŠ¤í‚¹ ì ìš©
            if use_center_mask:
                image = apply_center_mask(image, mask_ratio)
            
            inputs = processor(images=image, return_tensors="pt")
            
            with torch.no_grad():
                outputs = model(**inputs)
                logits = outputs.logits
                probs = torch.nn.functional.softmax(logits, dim=1).squeeze().tolist()
            
            pred_label = 0 if probs[0] > probs[1] else 1
            predictions.append(pred_label)
            true_labels.append(true_label)
            
            # í‹€ë¦° ì˜ˆì¸¡ ê¸°ë¡
            if pred_label != true_label:
                incorrect_samples.append({
                    "image_path": img_path,
                    "true_label": "Indoor" if true_label == 0 else "Outdoor",
                    "predicted_label": "Indoor" if pred_label == 0 else "Outdoor",
                    "confidence": max(probs),
                    "scores": {"Indoor": probs[0], "Outdoor": probs[1]}
                })
            
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if (idx + 1) % 10 == 0:
                print(f"ì§„í–‰: {idx + 1}/{len(val_paths)}")
        except Exception as e:
            print(f"âš ï¸  ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ ({img_path}): {e}")
            continue
    
    # ê²°ê³¼ ê³„ì‚°
    accuracy = sum([p == t for p, t in zip(predictions, true_labels)]) / len(true_labels)
    conf_matrix = confusion_matrix(true_labels, predictions)
    class_report = classification_report(
        true_labels, predictions, 
        target_names=["Indoor", "Outdoor"],
        digits=4
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“Š í‰ê°€ ê²°ê³¼")
    print("=" * 60)
    print(f"ì „ì²´ ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"\nConfusion Matrix:")
    print(f"                Predicted")
    print(f"                Indoor  Outdoor")
    print(f"Actual Indoor   {conf_matrix[0][0]:6d}  {conf_matrix[0][1]:7d}")
    print(f"       Outdoor  {conf_matrix[1][0]:6d}  {conf_matrix[1][1]:7d}")
    print(f"\n{class_report}")
    
    # í‹€ë¦° ì˜ˆì¸¡ ë¶„ì„
    if incorrect_samples:
        print("\n" + "=" * 60)
        print(f"âŒ í‹€ë¦° ì˜ˆì¸¡ ìƒ˜í”Œ ({len(incorrect_samples)}ê°œ)")
        print("=" * 60)
        for i, sample in enumerate(incorrect_samples[:30], 1):
            print(f"\n[{i}] {os.path.basename(sample['image_path'])}")
            print(f"    ì‹¤ì œ: {sample['true_label']}")
            print(f"    ì˜ˆì¸¡: {sample['predicted_label']} (ì‹ ë¢°ë„: {sample['confidence']:.4f})")
            print(f"    ì ìˆ˜: Indoor={sample['scores']['Indoor']:.4f}, "
                  f"Outdoor={sample['scores']['Outdoor']:.4f}")
        
        if len(incorrect_samples) > 30:
            print(f"\n... ê·¸ ì™¸ {len(incorrect_samples) - 30}ê°œ")
    
    # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    result_data = {
        "accuracy": float(accuracy),
        "total_samples": len(val_labels),
        "correct_predictions": int(accuracy * len(val_labels)),
        "confusion_matrix": conf_matrix.tolist(),
        "classification_report": class_report,
        "incorrect_samples": incorrect_samples
    }
    
    save_dir = os.path.dirname(model_path) if os.path.isfile(model_path) else model_path
    result_file = os.path.join(save_dir, "evaluation_results.json")
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… í‰ê°€ ê²°ê³¼ ì €ì¥: {result_file}")
    
    return result_data

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ê²½ë¡œ ì„¤ì •
    MODEL_DIR = "/workspace/indooroutdoor_dataset/final_model"  # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
    DATA_DIR = "/workspace/indooroutdoor_dataset"  # ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
    
    print("\n" + "ğŸ” Validation í‰ê°€ ì‹œì‘" + "\n")
    
    # í‰ê°€ ì‹¤í–‰
    evaluation_results = evaluate_model(
        model_path=MODEL_DIR,
        data_dir=DATA_DIR,
        use_center_mask=False,  # í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì„¤ì •ê³¼ ë™ì¼í•˜ê²Œ
        mask_ratio=0.6
    )
    
    if evaluation_results:
        print("\nâœ… í‰ê°€ ì™„ë£Œ!")
    else:
        print("\nâŒ í‰ê°€ ì‹¤íŒ¨")